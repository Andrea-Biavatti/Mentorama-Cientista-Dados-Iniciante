{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercício: Regressão Linear:\n",
    "__Parte 1:__\n",
    "\n",
    "1- Usando a função getData(), carregue os dados disponibilizados.\n",
    "\n",
    "2- Separe parte dos dados para o dataset de teste.\n",
    "\n",
    "3- Usando a metodologia de validação cruzada, teste diferentes parâmetros da regLinear - diferentes learning_rates e num_steps - para escolher a melhor combinação de parâmetros.\n",
    "\n",
    "4- Implemente a regressão linear do scikit-learn e compare os resultados obtidos.\n",
    "\n",
    "\n",
    "__Parte 2 (Introdução):__\n",
    "\n",
    "Para cada variável explicativa $X_1, .., X_5$, crie outras variáveis usando o __quadrado__ de cada um delas. Desta forma, o conjunto final será de 10 variáveis, em que:\n",
    "\n",
    "$X_6 = (X_1)^{2}$, $X_7 = (X_2)^{2}$, $X_8 = (X_3)^{2}$, $X_9 = (X_4)^{2}$, $X_{10} = (X_5)^{2}$.\n",
    "\n",
    "Ao treinarmos uma regressão linear com essas 10 variáveis, a predição é da forma:\n",
    "\n",
    "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2}$\n",
    "\n",
    "Como estamos usando o quadrado das variáveis explicativas, dizemos que temos um __modelo de regressão polinomial de grau 2__. Podemos ter variações deste modelo:\n",
    "\n",
    "-Podemos aumentar o grau: basta mudar a potência que elevamos as variáveis. Por exemplo, podemos incluir o __cubo__ das variáveis e termos um modelo polinomial de ordem 3.\n",
    "\n",
    "-Podemos ter __interações__ entre as variáveis: multiplicações entre as variáveis.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2} + \\theta_{11} \\cdot (X_1)^{3} + \\theta_{12} \\cdot V1 + \\theta_{13} \\cdot V2$,\n",
    "\n",
    "onde\n",
    "\n",
    "$V_1 = X_1 \\cdot X_2$ e $V_2 = (X_2)^{2} \\cdot X_4$\n",
    "\n",
    "__Parte 2 (Exercício):__\n",
    "\n",
    "1- Estude o link:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "em que é discutido como criar modelos polinomiais com o scikit-learn de forma detalhada.\n",
    "\n",
    "2- Repita os passos da primeira parte, mas agora considerando polinômios de graus 2 ou mais.\n",
    "\n",
    "3- Inclua regularização Ridge e Lasso nas análises e teste os resultados para diferentes parâmetros $\\alpha$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Exercício: Regressão Logística:\n",
    "\n",
    "__Parte 1:__\n",
    "\n",
    "Crie uma classe regLogistica para treinar o modelo de regressão logística. Essa classe deve ser usada para problemas de classificação binária, cuja variável target assume os valores: 0 (classe negativa) e 1 (classe positiva).\n",
    "\n",
    "O método construtor dessa classe deve possuir 3 parâmetros: learning_rate, num_steps e limiar.\n",
    "\n",
    "Os outros médotos devem ser:\n",
    "\n",
    "    - médoto fit: para treinar o modelo - usando gradient descent\n",
    "    \n",
    "    - médoto predict_proba: para retornar a probabilidade da classe 1\n",
    "    \n",
    "    - médoto predict: retornar a classe predita: 0 ou 1 - dependente do limiar\n",
    "    \n",
    "__Parte 2:__\n",
    "\n",
    "Usando a função getData2(), carregue o dataset disponibilizado.\n",
    "\n",
    "Use a regLogistica, classe criada na parte 1 do exercício, para treinar modelos nestes dados. Use validação cruzada para seleção dos parâmetros. Considere diferentes métricas de classificação e justifique as escolhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1: Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_friedman1, make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para acessar os dados do exercício 1\n",
    "\n",
    "def getData():\n",
    "    X, y = make_friedman1(n_samples = 10000, n_features = 5, noise = 5.0, random_state = 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Usando a função getData(), carregue os dados disponibilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = getData()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 , 0.71518937, 0.60276338, 0.54488318, 0.4236548 ],\n",
       "       [0.64589411, 0.43758721, 0.891773  , 0.96366276, 0.38344152],\n",
       "       [0.79172504, 0.52889492, 0.56804456, 0.92559664, 0.07103606],\n",
       "       ...,\n",
       "       [0.2558884 , 0.19185257, 0.31889167, 0.97098671, 0.45826743],\n",
       "       [0.65071484, 0.87733698, 0.60242322, 0.42648218, 0.65573615],\n",
       "       [0.5463288 , 0.69331045, 0.23367488, 0.83092388, 0.55131786]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.28814034, 21.53563265, 15.33477388, ..., 13.55427826,\n",
       "       20.05388514, 18.67813117])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.arange(0,len(X),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.scatter(X1, y, c = 'blue')\n",
    "plt.xlabel(\"X\", fontsize = 14, fontweight = 'bold')\n",
    "plt.ylabel(\"y\", fontsize = 14, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Separe parte dos dados para o dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como os dados já estão aleatorizado, a separação foi feita com 7500 instâncias para treino e 2500 para teste\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = X[:7500], X[7500:], y[:7500], y[7500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 5), (2500, 5), (7500,), (2500,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain1=np.arange(0,len(Xtrain),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Usando a metodologia de validação cruzada, teste diferentes parâmetros da regLinear - diferentes learning_rates e num_steps - para escolher a melhor combinação de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classe regLinear para exercício\n",
    "\n",
    "class regLinear():\n",
    "    \n",
    "    def __init__(self, learning_rate, num_steps):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_steps = num_steps\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        y = y.reshape(-1,1)\n",
    "        m = X.shape[0] \n",
    "        k = X.shape[1] \n",
    "        theta = np.random.randn(k+1,1) \n",
    "        X_b = np.c_[np.ones((m, 1)), X] \n",
    "        for step in range(self.num_steps):\n",
    "            gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "            theta = theta - self.learning_rate * gradients\n",
    "        self.theta_final = theta\n",
    "        print(\"modelo treinado.\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        X_b = np.c_[np.ones((m, 1)), X]\n",
    "        preds = X_b.dot(self.theta_final)\n",
    "        return preds.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = regLinear(learning_rate = 0.075, num_steps = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo treinado.\n"
     ]
    }
   ],
   "source": [
    "rg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.33741873],\n",
       "       [ 5.3025595 ],\n",
       "       [ 6.14172195],\n",
       "       [-0.15608272],\n",
       "       [ 9.32288933],\n",
       "       [ 3.6626737 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.theta_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.17754318, 18.69920175, 18.58466838, ..., 11.43276925,\n",
       "       12.30601453, 15.80539562])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Implemente a regressão linear do scikit-learn e compare os resultados obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.17502201577241294,\n",
       " array([ 6.34642766,  7.32237956,  0.22274329, 10.58969836,  4.66476975]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_, lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.42553332, 19.3204787 , 18.98205719, ..., 10.69464464,\n",
       "       11.82863968, 16.26278406])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados foram similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Repita os passos da primeira parte, mas agora considerando polinômios de graus 2 ou mais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando a função\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma função polinomial de ordem 2\n",
    "poly_features = PolynomialFeatures(degree = 2, include_bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 20)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_poly = poly_features.fit_transform(Xtrain)\n",
    "Xtrain_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.48813504e-01, 7.15189366e-01, 6.02763376e-01, 5.44883183e-01,\n",
       "        4.23654799e-01, 3.01196262e-01, 3.92505582e-01, 3.30804680e-01,\n",
       "        2.99039249e-01, 2.32507475e-01, 5.11495830e-01, 4.31089957e-01,\n",
       "        3.89694658e-01, 3.02993407e-01, 3.63323688e-01, 3.28435627e-01,\n",
       "        2.55363597e-01, 2.96897683e-01, 2.30842376e-01, 1.79483389e-01],\n",
       "       [6.45894113e-01, 4.37587211e-01, 8.91773001e-01, 9.63662761e-01,\n",
       "        3.83441519e-01, 4.17179205e-01, 2.82635004e-01, 5.75990931e-01,\n",
       "        6.22424104e-01, 2.47662620e-01, 1.91482567e-01, 3.90228460e-01,\n",
       "        4.21686500e-01, 1.67789105e-01, 7.95259085e-01, 8.59368432e-01,\n",
       "        3.41942794e-01, 9.28645916e-01, 3.69508313e-01, 1.47027398e-01],\n",
       "       [7.91725038e-01, 5.28894920e-01, 5.68044561e-01, 9.25596638e-01,\n",
       "        7.10360582e-02, 6.26828536e-01, 4.18739350e-01, 4.49735102e-01,\n",
       "        7.32818034e-01, 5.62410259e-02, 2.79729836e-01, 3.00435883e-01,\n",
       "        4.89543360e-01, 3.75706103e-02, 3.22674623e-01, 5.25780136e-01,\n",
       "        4.03516465e-02, 8.56729137e-01, 6.57507367e-02, 5.04612156e-03],\n",
       "       [8.71292997e-02, 2.02183974e-02, 8.32619846e-01, 7.78156751e-01,\n",
       "        8.70012148e-01, 7.59151487e-03, 1.76161481e-03, 7.25455841e-02,\n",
       "        6.78002528e-02, 7.58035492e-02, 4.08783595e-04, 1.68342390e-02,\n",
       "        1.57330825e-02, 1.75902514e-02, 6.93255807e-01, 6.47908754e-01,\n",
       "        7.24389380e-01, 6.05527929e-01, 6.77005827e-01, 7.56921138e-01],\n",
       "       [9.78618342e-01, 7.99158564e-01, 4.61479362e-01, 7.80529176e-01,\n",
       "        1.18274426e-01, 9.57693860e-01, 7.82071229e-01, 4.51612168e-01,\n",
       "        7.63840169e-01, 1.15745523e-01, 6.38654411e-01, 3.68795185e-01,\n",
       "        6.23766576e-01, 9.45200204e-02, 2.12963202e-01, 3.60198106e-01,\n",
       "        5.45812066e-02, 6.09225795e-01, 9.23166402e-02, 1.39888398e-02],\n",
       "       [6.39921021e-01, 1.43353287e-01, 9.44668917e-01, 5.21848322e-01,\n",
       "        4.14661940e-01, 4.09498914e-01, 9.17347821e-02, 6.04513498e-01,\n",
       "        3.33941711e-01, 2.65350892e-01, 2.05501650e-02, 1.35421395e-01,\n",
       "        7.48086725e-02, 5.94431523e-02, 8.92399363e-01, 4.92973889e-01,\n",
       "        3.91718246e-01, 2.72325671e-01, 2.16390637e-01, 1.71944524e-01],\n",
       "       [2.64555612e-01, 7.74233689e-01, 4.56150332e-01, 5.68433949e-01,\n",
       "        1.87898004e-02, 6.99896719e-02, 2.04827868e-01, 1.20677130e-01,\n",
       "        1.50382391e-01, 4.97094716e-03, 5.99437806e-01, 3.53166955e-01,\n",
       "        4.40100713e-01, 1.45476965e-02, 2.08073126e-01, 2.59291335e-01,\n",
       "        8.57097371e-03, 3.23117154e-01, 1.06807605e-02, 3.53056600e-04],\n",
       "       [6.17635497e-01, 6.12095723e-01, 6.16933997e-01, 9.43748079e-01,\n",
       "        6.81820299e-01, 3.81473607e-01, 3.78052046e-01, 3.81040336e-01,\n",
       "        5.82892314e-01, 4.21116419e-01, 3.74661174e-01, 3.77622661e-01,\n",
       "        5.77664162e-01, 4.17339289e-01, 3.80607556e-01, 5.82230274e-01,\n",
       "        4.20638122e-01, 8.90660436e-01, 6.43466597e-01, 4.64878920e-01],\n",
       "       [3.59507901e-01, 4.37031954e-01, 6.97631196e-01, 6.02254716e-02,\n",
       "        6.66766715e-01, 1.29245931e-01, 1.57116440e-01, 2.50803927e-01,\n",
       "        2.16515329e-02, 2.39707902e-01, 1.90996929e-01, 3.04887125e-01,\n",
       "        2.63204555e-02, 2.91398360e-01, 4.86689286e-01, 4.20151678e-02,\n",
       "        4.65157261e-01, 3.62710743e-03, 4.01563399e-02, 4.44577853e-01],\n",
       "       [6.70637870e-01, 2.10382561e-01, 1.28926298e-01, 3.15428351e-01,\n",
       "        3.63710771e-01, 4.49755152e-01, 1.41090513e-01, 8.64628576e-02,\n",
       "        2.11538197e-01, 2.43918217e-01, 4.42608220e-02, 2.71238447e-02,\n",
       "        6.63606243e-02, 7.65184035e-02, 1.66219902e-02, 4.06670095e-02,\n",
       "        4.68918831e-02, 9.94950446e-02, 1.14724689e-01, 1.32285525e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_poly[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22128329903067723,\n",
       " array([ 1.83038276e+01,  1.90862348e+01, -2.15788698e+01,  7.91467118e+00,\n",
       "         5.11421052e+00, -1.25388135e+01, -2.59190937e-03,  1.62596449e-01,\n",
       "         1.30648628e+00, -1.95537201e-01, -1.21029752e+01,  4.10000805e-01,\n",
       "         6.41601799e-01, -5.36078784e-01,  2.06897119e+01,  1.57215660e+00,\n",
       "        -2.01658918e-01,  6.92060407e-01,  4.38505005e-01, -1.52141136e-01]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_fit = LinearRegression() #também poderíamos ter usado nossa classe regLinear com gradient descent\n",
    "poly_fit.fit(Xtrain_poly, ytrain)\n",
    "\n",
    "poly_fit.intercept_, poly_fit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício: Regressão Logística:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 1:\n",
    "\n",
    "Crie uma classe regLogistica para treinar o modelo de regressão logística. Essa classe deve ser usada para problemas de classificação binária, cuja variável target assume os valores: 0 (classe negativa) e 1 (classe positiva).\n",
    "\n",
    "O método construtor dessa classe deve possuir 3 parâmetros: learning_rate, num_steps e limiar.\n",
    "\n",
    "Os outros médotos devem ser:\n",
    "\n",
    "- médoto fit: para treinar o modelo - usando gradient descent\n",
    "\n",
    "- médoto predict_proba: para retornar a probabilidade da classe 1\n",
    "\n",
    "- médoto predict: retornar a classe predita: 0 ou 1 - dependente do limiar\n",
    "Parte 2:\n",
    "\n",
    "Usando a função getData2(), carregue o dataset disponibilizado.\n",
    "\n",
    "Use a regLogistica, classe criada na parte 1 do exercício, para treinar modelos nestes dados. Use validação cruzada para seleção dos parâmetros. Considere diferentes métricas de classificação e justifique as escolhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para acessar os dados do exercício 2\n",
    "\n",
    "def getData2():\n",
    "    X, y = make_classification(n_classes=2, n_features=5, n_samples=10000, random_state = 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5), (10000,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = getData2()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementando a função de perda logarítmica - Log Loss\n",
    "\n",
    "def logLossCost(ytrue, ypred_probs):\n",
    "    return (ytrue * np.log(ypred_probs) + (1 - ytrue) * np.log(1 - ypred_probs)).mean() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passo: 0\n",
      "theta: [-0.10975646 -1.59101152  0.09648674 -0.50366782  0.69843334  1.30565748]\n",
      "Log Loss: 1.1334217439048748\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 1\n",
      "theta: [-49.00564345  50.99435655  50.99435655 ... -17.08581395 -17.08581395\n",
      " -17.08581395]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 2\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070005  -9.78070005\n",
      "  -9.78070005]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 3\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070005  -9.78070005\n",
      "  -9.78070005]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 4\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070005  -9.78070005\n",
      "  -9.78070005]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 5\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070004  -9.78070004\n",
      "  -9.78070004]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 6\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070004  -9.78070004\n",
      "  -9.78070004]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 7\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070004  -9.78070004\n",
      "  -9.78070004]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 8\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070003  -9.78070003\n",
      "  -9.78070003]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 9\n",
      "theta: [-64.73435749  66.3542508   66.3542508  ...  -9.78070003  -9.78070003\n",
      "  -9.78070003]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 10\n",
      "theta: [-64.7343575   66.3542508   66.3542508  ...  -9.78070002  -9.78070002\n",
      "  -9.78070002]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 11\n",
      "theta: [-64.7343575   66.3542508   66.3542508  ...  -9.78070002  -9.78070002\n",
      "  -9.78070002]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 12\n",
      "theta: [-64.7343575   66.3542508   66.3542508  ...  -9.78070002  -9.78070002\n",
      "  -9.78070002]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 13\n",
      "theta: [-64.7343575   66.3542508   66.3542508  ...  -9.78070001  -9.78070001\n",
      "  -9.78070001]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 14\n",
      "theta: [-64.7343575   66.3542508   66.3542508  ...  -9.78070001  -9.78070001\n",
      "  -9.78070001]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 15\n",
      "theta: [-64.7343575  66.3542508  66.3542508 ...  -9.7807     -9.7807\n",
      "  -9.7807   ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 16\n",
      "theta: [-64.7343575  66.3542508  66.3542508 ...  -9.7807     -9.7807\n",
      "  -9.7807   ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 17\n",
      "theta: [-64.7343575  66.3542508  66.3542508 ...  -9.7807     -9.7807\n",
      "  -9.7807   ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 18\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069999  -9.78069999\n",
      "  -9.78069999]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 19\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069999  -9.78069999\n",
      "  -9.78069999]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 20\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069999  -9.78069999\n",
      "  -9.78069999]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 21\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069998  -9.78069998\n",
      "  -9.78069998]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 22\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069998  -9.78069998\n",
      "  -9.78069998]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 23\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069997  -9.78069997\n",
      "  -9.78069997]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 24\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069997  -9.78069997\n",
      "  -9.78069997]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 25\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069997  -9.78069997\n",
      "  -9.78069997]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 26\n",
      "theta: [-64.73435751  66.3542508   66.3542508  ...  -9.78069996  -9.78069996\n",
      "  -9.78069996]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 27\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069996  -9.78069996\n",
      "  -9.78069996]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 28\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069995  -9.78069995\n",
      "  -9.78069995]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 29\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069995  -9.78069995\n",
      "  -9.78069995]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 30\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069995  -9.78069995\n",
      "  -9.78069995]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 31\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069994  -9.78069994\n",
      "  -9.78069994]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 32\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069994  -9.78069994\n",
      "  -9.78069994]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 33\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069994  -9.78069994\n",
      "  -9.78069994]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 34\n",
      "theta: [-64.73435752  66.3542508   66.3542508  ...  -9.78069993  -9.78069993\n",
      "  -9.78069993]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 35\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.78069993  -9.78069993\n",
      "  -9.78069993]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 36\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.78069992  -9.78069992\n",
      "  -9.78069992]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 37\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.78069992  -9.78069992\n",
      "  -9.78069992]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 38\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.78069992  -9.78069992\n",
      "  -9.78069992]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 39\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.78069991  -9.78069991\n",
      "  -9.78069991]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 40\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.78069991  -9.78069991\n",
      "  -9.78069991]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 41\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.7806999   -9.7806999\n",
      "  -9.7806999 ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 42\n",
      "theta: [-64.73435753  66.3542508   66.3542508  ...  -9.7806999   -9.7806999\n",
      "  -9.7806999 ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 43\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.7806999   -9.7806999\n",
      "  -9.7806999 ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 44\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069989  -9.78069989\n",
      "  -9.78069989]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 45\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069989  -9.78069989\n",
      "  -9.78069989]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 46\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069989  -9.78069989\n",
      "  -9.78069989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 47\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069988  -9.78069988\n",
      "  -9.78069988]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 48\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069988  -9.78069988\n",
      "  -9.78069988]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 49\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069987  -9.78069987\n",
      "  -9.78069987]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 50\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069987  -9.78069987\n",
      "  -9.78069987]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 51\n",
      "theta: [-64.73435754  66.3542508   66.3542508  ...  -9.78069987  -9.78069987\n",
      "  -9.78069987]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 52\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069986  -9.78069986\n",
      "  -9.78069986]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 53\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069986  -9.78069986\n",
      "  -9.78069986]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 54\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069985  -9.78069985\n",
      "  -9.78069985]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 55\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069985  -9.78069985\n",
      "  -9.78069985]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 56\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069985  -9.78069985\n",
      "  -9.78069985]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 57\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069984  -9.78069984\n",
      "  -9.78069984]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 58\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069984  -9.78069984\n",
      "  -9.78069984]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 59\n",
      "theta: [-64.73435755  66.3542508   66.3542508  ...  -9.78069983  -9.78069983\n",
      "  -9.78069983]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 60\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069983  -9.78069983\n",
      "  -9.78069983]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 61\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069983  -9.78069983\n",
      "  -9.78069983]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 62\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069982  -9.78069982\n",
      "  -9.78069982]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 63\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069982  -9.78069982\n",
      "  -9.78069982]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 64\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069982  -9.78069982\n",
      "  -9.78069982]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 65\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069981  -9.78069981\n",
      "  -9.78069981]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 66\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.78069981  -9.78069981\n",
      "  -9.78069981]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 67\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.7806998   -9.7806998\n",
      "  -9.7806998 ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 68\n",
      "theta: [-64.73435756  66.3542508   66.3542508  ...  -9.7806998   -9.7806998\n",
      "  -9.7806998 ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 69\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.7806998   -9.7806998\n",
      "  -9.7806998 ]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 70\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069979  -9.78069979\n",
      "  -9.78069979]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 71\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069979  -9.78069979\n",
      "  -9.78069979]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 72\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069978  -9.78069978\n",
      "  -9.78069978]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 73\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069978  -9.78069978\n",
      "  -9.78069978]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 74\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069978  -9.78069978\n",
      "  -9.78069978]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 75\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069977  -9.78069977\n",
      "  -9.78069977]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 76\n",
      "theta: [-64.73435757  66.3542508   66.3542508  ...  -9.78069977  -9.78069977\n",
      "  -9.78069977]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 77\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069977  -9.78069977\n",
      "  -9.78069977]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 78\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069976  -9.78069976\n",
      "  -9.78069976]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 79\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069976  -9.78069976\n",
      "  -9.78069976]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 80\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069975  -9.78069975\n",
      "  -9.78069975]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 81\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069975  -9.78069975\n",
      "  -9.78069975]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 82\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069975  -9.78069975\n",
      "  -9.78069975]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 83\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069974  -9.78069974\n",
      "  -9.78069974]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 84\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069974  -9.78069974\n",
      "  -9.78069974]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 85\n",
      "theta: [-64.73435758  66.3542508   66.3542508  ...  -9.78069973  -9.78069973\n",
      "  -9.78069973]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 86\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069973  -9.78069973\n",
      "  -9.78069973]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 87\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069973  -9.78069973\n",
      "  -9.78069973]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 88\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069972  -9.78069972\n",
      "  -9.78069972]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 89\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069972  -9.78069972\n",
      "  -9.78069972]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 90\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069972  -9.78069972\n",
      "  -9.78069972]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 91\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069971  -9.78069971\n",
      "  -9.78069971]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 92\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.78069971  -9.78069971\n",
      "  -9.78069971]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 93\n",
      "theta: [-64.73435759  66.3542508   66.3542508  ...  -9.7806997   -9.7806997\n",
      "  -9.7806997 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 94\n",
      "theta: [-64.7343576  66.3542508  66.3542508 ...  -9.7806997  -9.7806997\n",
      "  -9.7806997]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 95\n",
      "theta: [-64.7343576  66.3542508  66.3542508 ...  -9.7806997  -9.7806997\n",
      "  -9.7806997]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 96\n",
      "theta: [-64.7343576   66.3542508   66.3542508  ...  -9.78069969  -9.78069969\n",
      "  -9.78069969]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 97\n",
      "theta: [-64.7343576   66.3542508   66.3542508  ...  -9.78069969  -9.78069969\n",
      "  -9.78069969]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 98\n",
      "theta: [-64.7343576   66.3542508   66.3542508  ...  -9.78069968  -9.78069968\n",
      "  -9.78069968]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "passo: 99\n",
      "theta: [-64.7343576   66.3542508   66.3542508  ...  -9.78069968  -9.78069968\n",
      "  -9.78069968]\n",
      "Log Loss: nan\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#implementação do gradient descent para treinamento da regressão logística\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_steps = 100\n",
    "\n",
    "#criando uma coluna de 1's no dataset X \n",
    "X_b = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "#instanciando um vetor de parâmetros theta aleatório\n",
    "theta = np.random.randn(X_b.shape[1],1)\n",
    "\n",
    "\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    print('passo:', step)\n",
    "    print('theta:', theta.reshape(-1,))\n",
    "    \n",
    "    #calculando a probabilidade \n",
    "    yscores = sigmoid(X_b.dot(theta))\n",
    "    \n",
    "    #calculando o gradiente da Log Loss\n",
    "    gradient = X_b.T.dot(yscores - y)\n",
    "    \n",
    "    #atualizando os pesos\n",
    "    theta = theta - learning_rate * gradient\n",
    "    \n",
    "    #calculando a Log Loss dentro do passo\n",
    "    logloss_step = logLossCost(ytrue = y, ypred_probs = yscores)\n",
    "    print(\"Log Loss:\", logloss_step)\n",
    "    print('\\n-----------------------------------------------------------\\n')\n",
    "    \n",
    "theta_final = theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.63932020e-36, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        6.63932020e-36, 6.63932020e-36, 6.63932020e-36],\n",
       "       [1.12247861e-21, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.12247861e-21, 1.12247861e-21, 1.12247861e-21],\n",
       "       [1.04490069e-26, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.04490069e-26, 1.04490069e-26, 1.04490069e-26],\n",
       "       ...,\n",
       "       [2.13262283e-20, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        2.13262283e-20, 2.13262283e-20, 2.13262283e-20],\n",
       "       [1.05521762e-22, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.05521762e-22, 1.05521762e-22, 1.05521762e-22],\n",
       "       [6.55159768e-19, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        6.55159768e-19, 6.55159768e-19, 6.55159768e-19]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fazendo as predições com o theta final\n",
    "\n",
    "probs = sigmoid(X_b.dot(theta_final))\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiar = 0.5\n",
    "ypred = np.where(probs > limiar, 1, 0)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
